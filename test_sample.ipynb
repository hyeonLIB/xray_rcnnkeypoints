{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\OrthopedicLAB\\anaconda3\\envs\\pytorch\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from typing import Tuple, List, Sequence, Callable, Dict\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "from torchvision.models.detection.rpn import AnchorGenerator\n",
    "from torchvision.models.detection import keypointrcnn_resnet50_fpn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_keypoints(\n",
    "    image: np.ndarray,\n",
    "    keypoints: np.ndarray,\n",
    "    edges: List[Tuple[int, int]] = None,\n",
    "    keypoint_names: Dict[int, str] = None, \n",
    "    boxes: bool = True,\n",
    "    bbox: np.ndarray = None,\n",
    "    color: Tuple[int, int, int] = None,\n",
    "    dpi: int = 200,\n",
    "    file_name: str = None\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "        image : np.ndarray\n",
    "        keypoints : np.ndarray\n",
    "        edges : List[Tuple(int, int)]\n",
    "        keypoint_names : Dict[int, str]\n",
    "        boxes : bool\n",
    "        color : Tuple(int, int, int)\n",
    "        dpi : int\n",
    "        file_name : str\n",
    "\n",
    "        이미지에 keypoints와 boundary box 에 해당하는 부분을 그려 시각화시키는 함수입니다.\n",
    "        color은 원하는 색상으로 레이블을 표현할 경우에 사용됩니다.\n",
    "        boxes는 boundary box를 표현하고 싶을 때 사용됩니다. (default = False)\n",
    "        keypoint_names은 각각 keypoint들에 이름을 표현하고 싶을 때 사용됩니다.\n",
    "        edges는 각 keypoints들에서 연결이 필요한 경우 두 점을 이어주는 선을 그리는데 사용됩니다.\n",
    "    \"\"\"\n",
    "    np.random.seed(42)\n",
    "    if color: # 색을 따로 지정해두지 않았을 경우\n",
    "        colors = color\n",
    "        if (boxes == True) & (bbox is not None):\n",
    "            color_bbox = 0 # 0 Femoral -> (124,252,0) | 1 Tibial -> (149, 53, 83)\n",
    "            for bbox_ in bbox:\n",
    "                x1, y1 = int(bbox_[0]), int(bbox_[1])\n",
    "                x2, y2 = int(bbox_[2]), int(bbox_[3])\n",
    "                \n",
    "                if color_bbox == 0:\n",
    "                    cv2.rectangle(image, (x1, y1), (x2, y2), colors, thickness=30)\n",
    "                    color_bbox += 1\n",
    "                elif color_bbox == 1:\n",
    "                    cv2.rectangle(image, (x1, y1), (x2, y2), colors, thickness=30)\n",
    "\n",
    "        for i, keypoint in enumerate(keypoints):\n",
    "            keypoint = [p[:2].astype(int) for p in keypoint]\n",
    "            for point in keypoint:\n",
    "                cv2.circle(\n",
    "                    image, \n",
    "                    tuple(point), \n",
    "                    3, colors, thickness=int(image.shape[0]*0.005), lineType=cv2.FILLED) \n",
    "\n",
    "            if keypoint_names is not None:\n",
    "                cv2.putText(\n",
    "                    image, \n",
    "                    f'{i}: {keypoint_names[i]}', \n",
    "                    tuple(point), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 3, (255, 255, 255), 1) # 0.5 000\n",
    "\n",
    "        if edges is not None:\n",
    "            keypoints = [*keypoints[0] , *keypoints[1]]\n",
    "            keypoints = [p[:2].astype(int) for p in keypoints]\n",
    "            for i, edge in enumerate(edges):\n",
    "                cv2.line(\n",
    "                    image, \n",
    "                    tuple(keypoints[edge[0]]),\n",
    "                    tuple(keypoints[edge[1]]),\n",
    "                    colors, thickness=int(image.shape[0]*0.002), lineType=cv2.LINE_AA)\n",
    "\n",
    "    else:\n",
    "        colors = {k: tuple(map(int, np.random.randint(0, 255, 3))) for k in range(4)} # len(keypoint_names)\n",
    "        # color_femoral = (124, 252, 0)\n",
    "        # color_tibial = (149, 53, 83)\n",
    "    \n",
    "        if (boxes == True) & (bbox is not None):\n",
    "            color_bbox = 0 # 0 Femoral -> (124,252,0) | 1 Tibial -> (149, 53, 83)\n",
    "            for bbox_ in bbox:\n",
    "                x1, y1 = int(bbox_[0]), int(bbox_[1])\n",
    "                x2, y2 = int(bbox_[2]), int(bbox_[3])\n",
    "                \n",
    "                if color_bbox == 0:\n",
    "                    cv2.rectangle(image, (x1, y1), (x2, y2), (124, 252, 0), thickness=30)\n",
    "                    color_bbox += 1\n",
    "                elif color_bbox == 1:\n",
    "                    cv2.rectangle(image, (x1, y1), (x2, y2), (149, 53, 83), thickness=30)\n",
    "\n",
    "        for i, keypoint in enumerate(keypoints):\n",
    "            keypoint = [p[:2].astype(int) for p in keypoint]\n",
    "            for point in keypoint:\n",
    "                cv2.circle(\n",
    "                    image, \n",
    "                    tuple(point), \n",
    "                    3, colors.get(i), thickness=int(image.shape[0]*0.005), lineType=cv2.FILLED) \n",
    "\n",
    "            if keypoint_names is not None:\n",
    "                cv2.putText(\n",
    "                    image, \n",
    "                    f'{i}: {keypoint_names[i]}', \n",
    "                    tuple(point), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 3, (255, 255, 255), 1) # 0.5 000\n",
    "\n",
    "        if edges is not None:\n",
    "            keypoints = [*keypoints[0] , *keypoints[1]]\n",
    "            keypoints = [p[:2].astype(int) for p in keypoints]\n",
    "            for i, edge in enumerate(edges):\n",
    "                cv2.line(\n",
    "                    image, \n",
    "                    tuple(keypoints[edge[0]]),\n",
    "                    tuple(keypoints[edge[1]]),\n",
    "                    colors.get(edge[0]), thickness=int(image.shape[0]*0.002), lineType=cv2.LINE_AA)\n",
    "\n",
    "    fig, ax = plt.subplots(dpi=dpi)\n",
    "    ax.imshow(image)\n",
    "    ax.axis('off')\n",
    "    plt.show()\n",
    "    if file_name is None:  # set file name\n",
    "        fig.savefig('example.png')\n",
    "    else:\n",
    "        file_name = file_name.replace('.jpg','')\n",
    "        fig.savefig(f'label_{file_name}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(num_keypoints, num_objects, weights_path=None):\n",
    "    '''\n",
    "    num_objects : int   | number of objects that you want to detect\n",
    "    num_keypoints : int | number of keypoints that you are interested in object\n",
    "    '''\n",
    "    anchor_generator = AnchorGenerator(sizes=(32, 64, 128, 256, 512), aspect_ratios=(0.25, 0.5, 0.75, 1.0, 2.0, 3.0, 4.0))\n",
    "    model = keypointrcnn_resnet50_fpn(\n",
    "                                    # weights=False,            # Is deprecated since 0.13, default = None (Annotated cause it occurs warnings)\n",
    "                                    # weights_backbone=True,    # Is deprecated since 0.13, default = ResNet50_Weights.IMAGENET1K_V1 (Annotated cause it occurs warnings)\n",
    "                                    num_keypoints=num_keypoints,\n",
    "                                    num_classes=num_objects,    # Background is the first class, objects are other classes\n",
    "                                    rpn_anchor_generator=anchor_generator\n",
    "                                )\n",
    "    if weights_path:\n",
    "        state_dict = torch.load(weights_path)\n",
    "        model.load_state_dict(state_dict)        \n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight files list that you can choose : \n",
      " ['__init__.py']\n",
      "\n",
      "\n",
      "image files list that you can choose : \n",
      " ['1-00744541L.jpg', '1-00744541R.jpg', '10-02287852L.jpg', '10-02287852R.jpg', '100-02454820L.jpg', '100-02454820R.jpg', '101-02014179L.jpg', '101-02014179R.jpg', '102-00389969L.jpg', '102-00389969R.jpg', '103-02299812L.jpg', '103-02299812R.jpg', '104-00453374L.jpg', '104-00453374R.jpg', '105-00765897L.jpg', '105-00765897R.jpg', '106-01035918L.jpg', '106-01035918R.jpg', '107-00542154L.jpg', '107-00542154R.jpg', '108-02162453L.jpg', '108-02162453R.jpg', '109-02238889L.jpg', '109-02238889R.jpg', '11-01026682L.jpg', '11-01026682R.jpg', '110-02292924L.jpg', '110-02292924R.jpg', '111-00608502L.jpg', '111-00608502R.jpg', '112-01001099L.jpg', '112-01001099R.jpg', '113-00864610L.jpg', '113-00864610R.jpg', '114-00656267L.jpg', '114-00656267R.jpg', '115-00796102L.jpg', '115-00796102R.jpg', '116-00258692L.jpg', '116-00258692R.jpg', '117-00749953L.jpg', '117-00749953R.jpg', '118-01075927L.jpg', '118-01075927R.jpg', '119-00580368L.jpg', '119-00580368R.jpg', '12-00126470L.jpg', '12-00126470R.jpg', '120-01000727L.jpg', '120-01000727R.jpg', '121-02229820L.jpg', '121-02229820R.jpg', '13-00900143L.jpg', '13-00900143R.jpg', '14-00463639L.jpg', '14-00463639R.jpg', '15-02239670L.jpg', '15-02239670R.jpg', '16-02045551L.jpg', '16-02045551R.jpg', '17-02227812L.jpg', '17-02227812R.jpg', '18-00746888L.jpg', '18-00746888R.jpg', '19-00325701L.jpg', '19-00325701R.jpg', '2-02432733L.jpg', '2-02432733R.jpg', '20-00125186L.jpg', '20-00125186R.jpg', '21-00746888L.jpg', '21-00746888R.jpg', '22-01025564L.jpg', '22-01025564R.jpg', '23-00242130L.jpg', '23-00242130R.jpg', '24-00758286L.jpg', '24-00758286R.jpg', '25-02060024L.jpg', '25-02060024R.jpg', '26-00980974L.jpg', '26-00980974R.jpg', '27-02345180L.jpg', '27-02345180R.jpg', '28-00894221L.jpg', '28-00894221R.jpg', '29-00318745L.jpg', '29-00318745R.jpg', '3-00195427L.jpg', '3-00195427R.jpg', '30-00931571L.jpg', '30-00931571R.jpg', '31-00606057L.jpg', '31-00606057R.jpg', '32-00614570L.jpg', '32-00614570R.jpg', '33-00975339L.jpg', '33-00975339R.jpg', '34-00425681L.jpg', '34-00425681R.jpg', '35-02047635L.jpg', '35-02047635R.jpg', '36-00177743L.jpg', '36-00177743R.jpg', '37-02238889L.jpg', '37-02238889R.jpg', '38-00680743L.jpg', '38-00680743R.jpg', '39-00503187L.jpg', '39-00503187R.jpg', '4-00406801L.jpg', '4-00406801R.jpg', '40-01053389L.jpg', '40-01053389R.jpg', '41-02067689L.jpg', '41-02067689R.jpg', '42-01073419L.jpg', '42-01073419R.jpg', '43-00361400L.jpg', '43-00361400R.jpg', '44-02357186L.jpg', '44-02357186R.jpg', '45-01010732L.jpg', '45-01010732R.jpg', '46-00468959L.jpg', '46-00468959R.jpg', '47-00619544L.jpg', '47-00619544R.jpg', '48-00247953L.jpg', '48-00247953R.jpg', '49-00247953L.jpg', '49-00247953R.jpg', '5-00582369L.jpg', '5-00582369R.jpg', '50-00905003L.jpg', '50-00905003R.jpg', '51-00746888L.jpg', '51-00746888R.jpg', '52-00746888L.jpg', '52-00746888R.jpg', '53-00415882L.jpg', '53-00415882R.jpg', '54-00181255L.jpg', '54-00181255R.jpg', '55-00994408L.jpg', '55-00994408R.jpg', '56-00182796L.jpg', '56-00182796R.jpg', '57-02411454L.jpg', '57-02411454R.jpg', '58-02262644L.jpg', '58-02262644R.jpg', '59-00224237L.jpg', '59-00224237R.jpg', '6-00555302L.jpg', '6-00555302R.jpg', '60-02228037L.jpg', '60-02228037R.jpg', '61-00483799L.jpg', '61-00483799R.jpg', '62-00746888L.jpg', '62-00746888R.jpg', '63-00671919L.jpg', '63-00671919R.jpg', '64-00489280L.jpg', '64-00489280R.jpg', '65-00442022L.jpg', '65-00442022R.jpg', '66-00799648L.jpg', '66-00799648R.jpg', '67-00637381L.jpg', '67-00637381R.jpg', '68-02132791L.jpg', '68-02132791R.jpg', '69-00639353L.jpg', '69-00639353R.jpg', '7-02244271L.jpg', '7-02244271R.jpg', '70-00437345L.jpg', '70-00437345R.jpg', '71-02065276L.jpg', '71-02065276R.jpg', '72-01034488L.jpg', '72-01034488R.jpg', '73-02317637L.jpg', '73-02317637R.jpg', '74-00900394L.jpg', '74-00900394R.jpg', '75-00150292L.jpg', '75-00150292R.jpg', '76-00821985L.jpg', '76-00821985R.jpg', '77-00399602L.jpg', '77-00399602R.jpg', '78-00517927L.jpg', '78-00517927R.jpg', '79-00397182L.jpg', '79-00397182R.jpg', '8-00363330L.jpg', '8-00363330R.jpg', '80-02288502L.jpg', '80-02288502R.jpg', '81-00603648L.jpg', '81-00603648R.jpg', '82-00601503L.jpg', '82-00601503R.jpg', '83-02260284L.jpg', '83-02260284R.jpg', '84-01071810L.jpg', '84-01071810R.jpg', '85-02453326L.jpg', '85-02453326R.jpg', '86-00498189L.jpg', '86-00498189R.jpg', '87-02398277L.jpg', '87-02398277R.jpg', '88-00451771L.jpg', '88-00451771R.jpg', '89-02454343L.jpg', '89-02454343R.jpg', '91-00776693L.jpg', '91-00776693R.jpg', '92-02163350L.jpg', '92-02163350R.jpg', '93-00616296L.jpg', '93-00616296R.jpg', '94-00955296L.jpg', '94-00955296R.jpg', '95-02429734L.jpg', '95-02429734R.jpg', '96-02220723L.jpg', '96-02220723R.jpg', '97-02468053L.jpg', '97-02468053R.jpg', '98-02455566L.jpg', '98-02455566R.jpg', '99-02042391L.jpg', '99-02042391R.jpg']\n"
     ]
    }
   ],
   "source": [
    "# 이미지를 테스트할 때 사용할 weight 파일과 이미지 파일을 선택하기 위해 어떤 파일들이 폴더에 있는지 확인합니다.\n",
    "weight_list = os.listdir('./weights')\n",
    "print(\"weight files list that you can choose : \\n\", weight_list)\n",
    "print(\"\\n\")\n",
    "image_list = os.listdir('./data/images')\n",
    "print(\"image files list that you can choose : \\n\", image_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 9000, 9000)\n",
      "[[[4.5248701e+03 1.4713257e+03 1.0000000e+00]\n",
      "  [4.6139463e+03 5.2367163e+03 1.0000000e+00]]\n",
      "\n",
      " [[4.5723057e+03 5.4360820e+03 1.0000000e+00]\n",
      "  [4.6170327e+03 8.3262363e+03 1.0000000e+00]]\n",
      "\n",
      " [[4.4026499e+03 8.9954102e+03 1.0000000e+00]\n",
      "  [5.0416875e+03 8.9954102e+03 1.0000000e+00]]\n",
      "\n",
      " [[4.5394292e+03 1.4506327e+03 1.0000000e+00]\n",
      "  [3.9115437e+03 3.7033528e+03 1.0000000e+00]]\n",
      "\n",
      " [[4.4007793e+03 8.9951719e+03 1.0000000e+00]\n",
      "  [5.1001685e+03 8.9951719e+03 1.0000000e+00]]\n",
      "\n",
      " [[4.5767222e+03 5.4437529e+03 1.0000000e+00]\n",
      "  [4.6213350e+03 8.3093555e+03 1.0000000e+00]]]\n"
     ]
    }
   ],
   "source": [
    "# 확인하고자 하는 이미지를 로드합니다.\n",
    "model_path = './weights'\n",
    "model_name = 'xray_rcnnkeypoints_weight_exp04.pth'\n",
    "# image_path = './images/10-02287852R.jpg'\n",
    "image_path = './data/images'\n",
    "# image_name = '19-00325701R.jpg'\n",
    "image_name = '13-00900143L.jpg'\n",
    "\n",
    "image = cv2.imread(os.path.join(image_path, image_name))\n",
    "image = image / 255\n",
    "image = image.transpose(2,0,1)\n",
    "print(image.shape)\n",
    "image = [torch.as_tensor(image, dtype=torch.float32)]\n",
    "\n",
    "# 이미지에 대해 keypoints detection를 진행할 weight file 을 로드합니다.\n",
    "# Prediction\n",
    "model = get_model(num_keypoints=2, num_objects=3)  # num_objects -> 3\n",
    "model.load_state_dict(torch.load(os.path.join(model_path, model_name)))\n",
    "model.eval()\n",
    "preds = model(image)\n",
    "keypoints = preds[0]['keypoints'].detach().numpy().copy()\n",
    "\n",
    "print(keypoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of detected objects :  5\n",
      "prediction scores of detected objects :  tensor([0.9971, 0.9892, 0.2489, 0.1637, 0.1315, 0.0786],\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor(1)\n",
      "tensor(2)\n",
      "\n",
      "predict keys :  dict_keys(['boxes', 'labels', 'scores', 'keypoints', 'keypoints_scores'])\n",
      "\n",
      "prediction [0] :  {'boxes': tensor([3929.1724,  926.1870, 4998.0879, 5467.1357], grad_fn=<SelectBackward0>), 'labels': tensor(1), 'scores': tensor(0.9971, grad_fn=<SelectBackward0>), 'keypoints': tensor([[4.5249e+03, 1.4713e+03, 1.0000e+00],\n",
      "        [4.6139e+03, 5.2367e+03, 1.0000e+00]], grad_fn=<SelectBackward0>), 'keypoints_scores': tensor([19.0046, 24.8745], grad_fn=<SelectBackward0>)}\n"
     ]
    }
   ],
   "source": [
    "# 이미지에서 keypoints 탐지를 진행하면 여러개의 결과값이 나오게 됩니다.\n",
    "# 각 결과값에서 score 가 높은 객체와 keypoints들만 선정하여 활용합니다. (정확도가 0.9 이상인 경우만)\n",
    "\n",
    "# dict_keys(['boxes', 'labels', 'scores', 'keypoints', 'keypoints_scores'])\n",
    "print(\"number of detected objects : \", len(preds[0]))\n",
    "print(\"prediction scores of detected objects : \",preds[0]['scores'])\n",
    "\n",
    "predicts = []\n",
    "\n",
    "for idx, score in enumerate(preds[0]['scores']):\n",
    "    if score > 0.9: # 정확도가 0.9 이상일 경우 해당 예측치만 모두 append\n",
    "        predicts.append({\n",
    "            'boxes':preds[0]['boxes'][idx],\n",
    "            'labels':preds[0]['labels'][idx],\n",
    "            'scores':preds[0]['scores'][idx],\n",
    "            'keypoints':preds[0]['keypoints'][idx],\n",
    "            'keypoints_scores':preds[0]['keypoints_scores'][idx],\n",
    "        })\n",
    "        print(preds[0]['labels'][idx])\n",
    "\n",
    "print(\"\\npredict keys : \", predicts[0].keys())\n",
    "print(\"\\nprediction [0] : \", predicts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # keypoints 탐지 결과를 시각화합니다.\n",
    "image = cv2.imread(os.path.join(image_path, image_name))\n",
    "\n",
    "keypoints = [predict['keypoints'].detach().numpy().copy() for predict in predicts]\n",
    "bboxes = [predict['boxes'].detach().numpy().copy() for predict in predicts]\n",
    "\n",
    "for bbox in bboxes:\n",
    "    bbox = np.array(bbox)\n",
    "    bbox = bbox.astype(np.int64)\n",
    "    \n",
    "keypoint_names = {\n",
    "    0: 'femoral-top',\n",
    "    1: 'femoral-bottom',\n",
    "    2: 'tibial-top',\n",
    "    3: 'tibial-bottom'\n",
    "}\n",
    "\n",
    "edges = [\n",
    "    (0, 1), (2, 3)\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "file_name='exampleee.png'\n",
    "draw_keypoints(image, keypoints, edges, keypoint_names, boxes=True, bbox=bboxes, dpi=400, color=(255,0,0), file_name=file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실제 레이블을 시각화하여 예측된 값들이 얼마나 실제를 잘 반영하는지 비교합니다.\n",
    "label_path = './data/annotations'\n",
    "label_id = image_name.replace('.jpg', '') + '.json'\n",
    "\n",
    "with open(os.path.join(label_path, label_id)) as f:\n",
    "    label_data = json.load(f)\n",
    "    annotated_bboxes = np.array([np.array(bbox).astype(np.int32) for bbox in label_data['bboxes']])\n",
    "    annotated_keypoints = np.array(label_data['keypoints'])\n",
    "    \n",
    "print(\"Prediction is red color\")\n",
    "draw_keypoints(image, annotated_keypoints, edges, keypoint_names, boxes=True, bbox=annotated_bboxes, dpi=400, file_name=file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The annotated femoral axis is :  [  75 3827]\n",
      "The annotated tibial axis is :  [  22 2894]\n",
      "The annotated femoral range is :  45.13618762608989\n",
      "The annotated tibial range is :  34.12668504102889\n",
      "The annotated HKA(Hip-Knee-Ankle) angle is :  -0.6871654196260051\n",
      "\n",
      "The predicted femoral axis is :  [  89.07617 3765.3906 ]\n",
      "The predicted tibial axis is :  [  44.72705 2890.1543 ]\n",
      "The predicted femoral range is :  44.41345452276905\n",
      "The predicted tibial range is :  34.08443318299079\n",
      "The prediction of HKA(Hip-Knee-Ankle) angle is :  -0.46855095\n"
     ]
    }
   ],
   "source": [
    "# keypoints들을 통해서 각각 femoral와 tibial에 해당하는 부분들을 구성하여 원하는 정보를 출력합니다.\n",
    "# femoral과 tibial이 이루는 HKA(Hip-Knee-Ankle), femoral과 tibial의 각 길이 등\n",
    "# 모델에서 예측한 keypoints들과 실제 레이블링 되었던 keypoints들을 비교합니다.\n",
    "pixel_spacing = 0.0117918794067591  #  실제 픽셀값과 사진에 나온 자를 통해서 각 픽셀이 실측치로 얼마인지 계산합니다. (정확한 값은 아닙니다.)\n",
    "\n",
    "annotated_femoral_axis = np.array(annotated_keypoints[0][1][:2]) - np.array(annotated_keypoints[0][0][:2])\n",
    "annotated_tibial_axis = np.array(annotated_keypoints[1][1][:2]) - np.array(annotated_keypoints[1][0][:2])\n",
    "annotated_femoral_range = np.linalg.norm(np.array(annotated_keypoints[0][1][:2]) - np.array(annotated_keypoints[0][0][:2])) * pixel_spacing\n",
    "annotated_tibial_range = np.linalg.norm(np.array(annotated_keypoints[1][1][:2]) - np.array(annotated_keypoints[1][0][:2])) * pixel_spacing\n",
    "annotated_angle = np.arctan2(annotated_femoral_axis[1], annotated_femoral_axis[0]) - np.arctan2(annotated_tibial_axis[1], annotated_tibial_axis[0])\n",
    "print(\"The annotated femoral axis is : \", annotated_femoral_axis)\n",
    "print(\"The annotated tibial axis is : \", annotated_tibial_axis)\n",
    "print(\"The annotated femoral range is : \", annotated_femoral_range)\n",
    "print(\"The annotated tibial range is : \", annotated_tibial_range)\n",
    "print(\"The annotated HKA(Hip-Knee-Ankle) angle is : \", np.degrees(annotated_angle)) # np.degrees -> radian 값을 degree 값으로 변환\n",
    "\n",
    "\n",
    "for idx, label in enumerate(predicts):\n",
    "    if label['labels'] == 1: # femoral\n",
    "        predicted_femoral_axis = np.array(keypoints[idx][1][:2]) - np.array(keypoints[idx][0][:2])\n",
    "        predicted_femoral_range = np.linalg.norm(np.array(keypoints[idx][1][:2]) - np.array(keypoints[idx][0][:2])) * pixel_spacing\n",
    "    elif label['labels'] == 2: # tibial\n",
    "        predicted_tibial_axis = np.array(keypoints[idx][1][:2]) - np.array(keypoints[idx][0][:2])\n",
    "        predicted_tibial_range = np.linalg.norm(np.array(keypoints[idx][1][:2]) - np.array(keypoints[idx][0][:2])) * pixel_spacing\n",
    "    else:\n",
    "        print('error')\n",
    "predicted_angle = np.arctan2(predicted_femoral_axis[1], predicted_femoral_axis[0]) - np.arctan2(predicted_tibial_axis[1], predicted_tibial_axis[0]) # for right side of legs\n",
    "print(\"\\nThe predicted femoral axis is : \", predicted_femoral_axis)\n",
    "print(\"The predicted tibial axis is : \", predicted_tibial_axis)\n",
    "print(\"The predicted femoral range is : \", predicted_femoral_range)\n",
    "print(\"The predicted tibial range is : \", predicted_tibial_range)\n",
    "print(\"The prediction of HKA(Hip-Knee-Ankle) angle is : \", np.degrees(predicted_angle))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9a647068bef9d1b4c199dcb654ad446e7fe933e02b6df42141d51a9adbaca517"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
